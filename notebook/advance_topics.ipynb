{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. pytest \n",
    "# 2. cache\n",
    "# 3. pydantic object and output parser\n",
    "# 4. token counter(cost analysis)\n",
    "# 5. history or memory \n",
    "# 6. evaluation\n",
    "# 7. guadrails\n",
    "# 8. adavance RAG\n",
    "\n",
    "## as a experiment will do in the notebook\n",
    "### then as a assignment you can integrate it in end to end project\n",
    "\n",
    "## Next Saturday there will demonstration of this concept (whoever will comeplete it\n",
    "# that person will give the demo)\n",
    "\n",
    "### next week satuday 2-2:30\n",
    "\n",
    "### then will start with the next project\n",
    "\n",
    "#For first winner there is prize money:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49527aa2",
   "metadata": {},
   "source": [
    "Assignment on first Project:\n",
    "1. you have to make enable this project for every document(.ppt,.docx,.md,.txt,.pdf,.xlxs,.csv,anysqldb)\n",
    "2. you have to add a code for dealing with table and images data also\n",
    "3. you have to add the evalation matrix using the DeepEval\n",
    "4. write at least 10 test cases\n",
    "5. this cases should be vaildate before the commit and after the commit\n",
    "6. add one login screen to your protal\n",
    "7. use the langchain inmemory cache and implement inside the project\n",
    "8. deadline for this assignment is till 5th of september(friday)\n",
    "9. inner will present the entire solution to the whole class (30 minute presentation would be there)\n",
    "10. prize: money or course or giftpack(there will be only one winnner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fb2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from utils.model_loader import ModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d950afbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-08-24T07:43:44.298823Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-08-24T07:43:44.299812Z\", \"level\": \"info\", \"event\": \"Loaded API_KEYS from ECS secret\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_m0...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-08-24T07:43:44.300812Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"faiss_db\", \"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-08-24T07:43:44.304824Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n"
     ]
    }
   ],
   "source": [
    "loader = ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6794aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-08-24T07:44:58.301931Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Loaded: model='models/gemini-2.0-flash' google_api_key=SecretStr('**********') temperature=0.0 max_output_tokens=2048 client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018A7A81B070> default_metadata=() model_kwargs={}\n",
      "LLM Result: I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings like humans do, but I am functioning optimally and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "llm = loader.load_llm()\n",
    "print(f\"LLM Loaded: {llm}\")\n",
    "result = llm.invoke(\"Hello, how are you?\")\n",
    "print(f\"LLM Result: {result.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eeb6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd17a47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb10b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give me a JSON with keys 'title' and 'summary' for this topic: {topic}\\n{format_instructions}\"\n",
    ").partial(format_instructions=parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7121d8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={'format_instructions': 'Return a JSON object.'}, template=\"Give me a JSON with keys 'title' and 'summary' for this topic: {topic}\\n{format_instructions}\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7a92f",
   "metadata": {},
   "source": [
    "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={'format_instructions': 'Return a JSON object.'}, template=\"Give me a JSON with keys 'title' and 'summary' for this topic: {topic}\\n{format_instructions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26281ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ec5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"topic\": \"LangChain for RAG\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf7461f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'LangChain for Retrieval Augmented Generation (RAG)',\n",
       " 'summary': 'LangChain simplifies the development of Retrieval Augmented Generation (RAG) applications. It provides modules for connecting to various data sources, creating embeddings, implementing retrieval strategies, and integrating with large language models (LLMs) to generate contextually relevant and informed responses. LangChain streamlines the RAG pipeline, enabling developers to build powerful question answering, chatbot, and knowledge-based systems more efficiently.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b2901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import OutputFixingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5503f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0d8be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing wrapper\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=json_parser, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551fc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broken JSON\n",
    "bad_output = \"\"\"\n",
    "title: LangChain RAG\n",
    "summary LangChain helps with retrieval augmented generation...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b20efef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fixed_result = fixing_parser.parse(bad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "542c0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'LangChain RAG', 'summary': 'LangChain helps with retrieval augmented generation...'}\n"
     ]
    }
   ],
   "source": [
    "print(fixed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98b00a",
   "metadata": {},
   "source": [
    "| Feature                | `JsonOutputParser`               | `OutputFixingParser`                     \n",
    "| ---------------------- | -------------------------------- | ---------------------------------------- \n",
    "| Purpose                | Enforce strict JSON              | Auto-correct bad/invalid output          \n",
    "| Works with             | Well-formed model responses only | Even with malformed model responses      \n",
    "| Raises error if broken | Yes                            |   No, it tries to fix using LLM          \n",
    "| Ideal for              | Strict structured output         | Fragile prompts, semi-structured outputs \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69055cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.output_parsers import OutputFixingParser\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# json_parser = JsonOutputParser()\n",
    "# safe_parser = OutputFixingParser.from_llm(parser=json_parser, llm=llm)\n",
    "\n",
    "# # Use safe_parser instead of json_parser\n",
    "# chain = prompt | llm | safe_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb4cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap with cache\n",
    "Model_Cache = {}\n",
    "\n",
    "import time\n",
    "def cached_model(query):\n",
    "    start_time = time.time()\n",
    "    if Model_Cache.get(query):\n",
    "        print(\"***CACHE HIT***\")\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        return Model_Cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        Model_Cache[query] = response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8832440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE HIT***\n",
      "EXECUTION TIME: 0.00 seconds\n",
      "content='Hi there! How can I help you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--2b56fd6b-b818-4b2c-a48a-8295d36db733-0' usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"hi\"\n",
    "response = cached_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d69528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 8.92 seconds\n",
      "content=\"## The Enduring Quest for Independence: A Multifaceted Human Imperative\\n\\nIndependence, a word that resonates with the spirit of freedom and self-determination, is a fundamental human aspiration. It is a concept that permeates our lives, shaping our individual identities, influencing our societal structures, and driving historical movements. From the toddler learning to walk to the nation striving for sovereignty, the pursuit of independence is a constant and multifaceted journey, encompassing personal autonomy, economic self-sufficiency, and political liberation. This essay will explore the various dimensions of independence, examining its significance, its challenges, and its enduring relevance in the modern world.\\n\\nAt its core, independence is about the ability to make choices and act upon them without undue external control. This begins at the individual level, where the development of personal autonomy is crucial for a fulfilling and meaningful life. As children, we are inherently dependent on our caregivers for survival. However, as we mature, we gradually strive for independence, learning to dress ourselves, make decisions about our education, and ultimately, chart our own course in life. This process of individuation, as psychologists call it, is essential for developing a strong sense of self and the confidence to navigate the complexities of the world.\\n\\nPersonal independence is not merely about physical self-sufficiency; it also encompasses intellectual and emotional autonomy. It involves the ability to think critically, form independent opinions, and resist the pressures of conformity. It requires the courage to question established norms, challenge conventional wisdom, and forge one's own path, even when it deviates from the expectations of others. Emotionally independent individuals are able to manage their own feelings, build healthy relationships, and avoid becoming overly reliant on others for validation or support. They possess a strong internal compass that guides their actions and allows them to make choices that align with their values and beliefs.\\n\\nHowever, the pursuit of personal independence is not without its challenges. Societal pressures, cultural norms, and economic realities can all act as constraints on individual autonomy. The pressure to conform to societal expectations, whether in terms of career choices, lifestyle, or personal relationships, can be immense. Economic dependence, particularly in societies with significant income inequality, can limit individuals' ability to make independent choices about their lives. Furthermore, internal barriers, such as fear of failure, lack of self-confidence, and ingrained patterns of dependence, can also hinder the development of personal autonomy.\\n\\nBeyond the individual level, independence also plays a crucial role in the economic sphere. Economic independence, whether for individuals, businesses, or nations, refers to the ability to sustain oneself without relying excessively on external support. For individuals, this means having the skills, education, and opportunities to earn a living and provide for their needs. For businesses, it means being able to compete effectively in the marketplace, generate profits, and reinvest in their growth. For nations, it means having a diversified economy, a strong industrial base, and the ability to trade freely with other countries.\\n\\nEconomic independence is essential for both individual and national prosperity. It allows individuals to pursue their passions, contribute to society, and build a secure future for themselves and their families. It empowers businesses to innovate, create jobs, and drive economic growth. It enables nations to control their own economic destiny, resist external pressures, and improve the living standards of their citizens.\\n\\nHowever, achieving economic independence is not always easy. Global competition, technological advancements, and economic downturns can all pose significant challenges. Individuals may struggle to find employment in a rapidly changing job market. Businesses may face intense competition from larger, more established companies. Nations may be vulnerable to economic shocks and external pressures from powerful trading partners.\\n\\nTherefore, fostering economic independence requires a multifaceted approach. It involves investing in education and training, promoting entrepreneurship and innovation, creating a supportive business environment, and ensuring fair trade practices. It also requires addressing issues of income inequality and providing social safety nets to protect vulnerable populations.\\n\\nPerhaps the most widely recognized form of independence is political independence, the right of a nation to govern itself without external interference. This is the foundation of national sovereignty and the cornerstone of international relations. The struggle for political independence has been a recurring theme throughout history, from the American Revolution to the decolonization movements of the 20th century.\\n\\nPolitical independence is not merely about the absence of foreign rule; it also encompasses the right of a nation to determine its own political system, laws, and policies. It involves the ability to choose its own leaders, make its own decisions, and pursue its own national interests. It is the foundation of democracy, self-determination, and the rule of law.\\n\\nHowever, achieving and maintaining political independence is a constant struggle. External threats, such as military aggression, economic coercion, and political interference, can undermine a nation's sovereignty. Internal challenges, such as political instability, corruption, and social divisions, can also weaken a nation's ability to govern itself effectively.\\n\\nTherefore, safeguarding political independence requires a strong national defense, a vibrant civil society, and a commitment to democratic principles. It also requires international cooperation and a respect for the sovereignty of all nations.\\n\\nIn the 21st century, the concept of independence is evolving in response to the challenges of globalization and technological advancements. The rise of interconnectedness and interdependence has blurred the lines between national sovereignty and international cooperation. The digital revolution has created new opportunities for individuals to connect, communicate, and collaborate across borders, but it has also raised concerns about privacy, security, and the control of information.\\n\\nIn this context, the pursuit of independence requires a more nuanced and sophisticated approach. It is no longer simply about achieving self-sufficiency or resisting external control. It is about finding a balance between autonomy and interdependence, between individual freedom and collective responsibility. It is about harnessing the power of technology to empower individuals and communities, while mitigating the risks of surveillance, manipulation, and inequality.\\n\\nUltimately, the quest for independence is an enduring human imperative. It is a journey that begins at the individual level and extends to the national and global levels. It is a process of continuous learning, adaptation, and innovation. It is a testament to the human spirit's unwavering desire for freedom, self-determination, and the ability to shape its own destiny. As we navigate the complexities of the modern world, the pursuit of independence remains as relevant and vital as ever, guiding us towards a future where individuals, communities, and nations can thrive in freedom and dignity. The challenge lies in understanding its multifaceted nature and striving for a balance that allows us to be both independent and interconnected, autonomous and responsible, free and secure. Only then can we truly realize the full potential of independence and build a more just and equitable world for all.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--62477a0a-a5c3-4cab-b5f9-c725c63ff355-0' usage_metadata={'input_tokens': 14, 'output_tokens': 1360, 'total_tokens': 1374, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 1000 words essay on independence?\"\n",
    "response = cached_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b9da868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE HIT***\n",
      "EXECUTION TIME: 0.00 seconds\n",
      "content=\"## The Enduring Quest for Independence: A Multifaceted Human Imperative\\n\\nIndependence, a word that resonates with the spirit of freedom and self-determination, is a fundamental human aspiration. It is a concept that permeates our lives, shaping our individual identities, influencing our societal structures, and driving historical movements. From the toddler learning to walk to the nation striving for sovereignty, the pursuit of independence is a constant and multifaceted journey, encompassing personal autonomy, economic self-sufficiency, and political liberation. This essay will explore the various dimensions of independence, examining its significance, its challenges, and its enduring relevance in the modern world.\\n\\nAt its core, independence is about the ability to make choices and act upon them without undue external control. This begins at the individual level, where the development of personal autonomy is crucial for a fulfilling and meaningful life. As children, we are inherently dependent on our caregivers for survival. However, as we mature, we gradually strive for independence, learning to dress ourselves, make decisions about our education, and ultimately, chart our own course in life. This process of individuation, as psychologists call it, is essential for developing a strong sense of self and the confidence to navigate the complexities of the world.\\n\\nPersonal independence is not merely about physical self-sufficiency; it also encompasses intellectual and emotional autonomy. It involves the ability to think critically, form independent opinions, and resist the pressures of conformity. It requires the courage to question established norms, challenge conventional wisdom, and forge one's own path, even when it deviates from the expectations of others. Emotionally independent individuals are able to manage their own feelings, build healthy relationships, and avoid becoming overly reliant on others for validation or support. They possess a strong internal compass that guides their actions and allows them to make choices that align with their values and beliefs.\\n\\nHowever, the pursuit of personal independence is not without its challenges. Societal pressures, cultural norms, and economic realities can all act as constraints on individual autonomy. The pressure to conform to societal expectations, whether in terms of career choices, lifestyle, or personal relationships, can be immense. Economic dependence, particularly in societies with significant income inequality, can limit individuals' ability to make independent choices about their lives. Furthermore, internal barriers, such as fear of failure, lack of self-confidence, and ingrained patterns of dependence, can also hinder the development of personal autonomy.\\n\\nBeyond the individual level, independence also plays a crucial role in the economic sphere. Economic independence, whether for individuals, businesses, or nations, refers to the ability to sustain oneself without relying excessively on external support. For individuals, this means having the skills, education, and opportunities to earn a living and provide for their needs. For businesses, it means being able to compete effectively in the marketplace, generate profits, and reinvest in their growth. For nations, it means having a diversified economy, a strong industrial base, and the ability to trade freely with other countries.\\n\\nEconomic independence is essential for both individual and national prosperity. It allows individuals to pursue their passions, contribute to society, and build a secure future for themselves and their families. It empowers businesses to innovate, create jobs, and drive economic growth. It enables nations to control their own economic destiny, resist external pressures, and improve the living standards of their citizens.\\n\\nHowever, achieving economic independence is not always easy. Global competition, technological advancements, and economic downturns can all pose significant challenges. Individuals may struggle to find employment in a rapidly changing job market. Businesses may face intense competition from larger, more established companies. Nations may be vulnerable to economic shocks and external pressures from powerful trading partners.\\n\\nTherefore, fostering economic independence requires a multifaceted approach. It involves investing in education and training, promoting entrepreneurship and innovation, creating a supportive business environment, and ensuring fair trade practices. It also requires addressing issues of income inequality and providing social safety nets to protect vulnerable populations.\\n\\nPerhaps the most widely recognized form of independence is political independence, the right of a nation to govern itself without external interference. This is the foundation of national sovereignty and the cornerstone of international relations. The struggle for political independence has been a recurring theme throughout history, from the American Revolution to the decolonization movements of the 20th century.\\n\\nPolitical independence is not merely about the absence of foreign rule; it also encompasses the right of a nation to determine its own political system, laws, and policies. It involves the ability to choose its own leaders, make its own decisions, and pursue its own national interests. It is the foundation of democracy, self-determination, and the rule of law.\\n\\nHowever, achieving and maintaining political independence is a constant struggle. External threats, such as military aggression, economic coercion, and political interference, can undermine a nation's sovereignty. Internal challenges, such as political instability, corruption, and social divisions, can also weaken a nation's ability to govern itself effectively.\\n\\nTherefore, safeguarding political independence requires a strong national defense, a vibrant civil society, and a commitment to democratic principles. It also requires international cooperation and a respect for the sovereignty of all nations.\\n\\nIn the 21st century, the concept of independence is evolving in response to the challenges of globalization and technological advancements. The rise of interconnectedness and interdependence has blurred the lines between national sovereignty and international cooperation. The digital revolution has created new opportunities for individuals to connect, communicate, and collaborate across borders, but it has also raised concerns about privacy, security, and the control of information.\\n\\nIn this context, the pursuit of independence requires a more nuanced and sophisticated approach. It is no longer simply about achieving self-sufficiency or resisting external control. It is about finding a balance between autonomy and interdependence, between individual freedom and collective responsibility. It is about harnessing the power of technology to empower individuals and communities, while mitigating the risks of surveillance, manipulation, and inequality.\\n\\nUltimately, the quest for independence is an enduring human imperative. It is a journey that begins at the individual level and extends to the national and global levels. It is a process of continuous learning, adaptation, and innovation. It is a testament to the human spirit's unwavering desire for freedom, self-determination, and the ability to shape its own destiny. As we navigate the complexities of the modern world, the pursuit of independence remains as relevant and vital as ever, guiding us towards a future where individuals, communities, and nations can thrive in freedom and dignity. The challenge lies in understanding its multifaceted nature and striving for a balance that allows us to be both independent and interconnected, autonomous and responsible, free and secure. Only then can we truly realize the full potential of independence and build a more just and equitable world for all.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--62477a0a-a5c3-4cab-b5f9-c725c63ff355-0' usage_metadata={'input_tokens': 14, 'output_tokens': 1360, 'total_tokens': 1374, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 1000 words essay on independence?\"\n",
    "response = cached_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc9aa9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-08-24T07:58:48.562915Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model Loaded: client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018A7BAAAAA0> async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x0000018A7BE60BB0> model='models/text-embedding-004' task_type=None google_api_key=SecretStr('**********') credentials=None client_options=None transport=None request_options=None\n",
      "Embedding Result: [0.012455824762582779, -0.022220758721232414, -0.050555989146232605, -0.04617856815457344, 0.007134224288165569, 0.03131191432476044, 0.03413437679409981, 0.002971651265397668, -0.010995007120072842, 0.04237418621778488, -0.01806010864675045, 0.02493678405880928, 0.1121494323015213, -0.013102629221975803, -0.0148635134100914, -0.024023527279496193, 0.010264375247061253, -0.0037090936675667763, -0.10687677562236786, -0.001329770078882575, 0.03868139907717705, -0.03769991546869278, 0.03614252060651779, 0.005920442286878824, -0.04356273636221886, -0.004675108939409256, -0.023465346544981003, -0.010386619716882706, 0.011209390126168728, -0.025817539542913437, 0.04684286192059517, 0.08373904973268509, 0.010084772482514381, -0.03376094251871109, 0.020884841680526733, 0.02289341762661934, -0.003998701926320791, 0.01330992579460144, 0.0509757325053215, -0.09198947250843048, -0.07254136353731155, 0.04478190466761589, -0.0014892473118379712, 0.03480713814496994, -0.002893605502322316, -0.021368319168686867, 0.026944760233163834, 0.03481404110789299, -0.0113154212012887, 0.04239237308502197, 0.028903041034936905, 0.022403204813599586, -0.05002392828464508, 0.006107809022068977, -0.006879379041492939, -0.0005574015085585415, 0.00018034980166703463, 0.008374546654522419, 0.04145769402384758, -0.025920633226633072, 0.00581536628305912, 0.007453762460500002, -0.015612686984241009, -0.03611474484205246, 0.014897655695676804, -0.037706803530454636, 0.011048460379242897, -0.005773257464170456, -0.07338972389698029, 0.041947416961193085, -0.008714448660612106, 0.013749705627560616, -0.05058510601520538, 0.008701021783053875, -0.026075800880789757, -0.010403540916740894, -0.010278790257871151, -0.005401624366641045, 0.011471167206764221, 0.033857714384794235, -0.04043952003121376, 0.015613697469234467, 0.06003198027610779, 0.07738664001226425, -0.023364201188087463, 0.029591014608740807, 0.01976163499057293, -0.06802070140838623, -0.05220983177423477, -0.010016380809247494, 0.10859932005405426, 0.011279468424618244, 0.007659756112843752, -0.015049867331981659, 0.06771127879619598, -0.01944717764854431, -0.08944784849882126, -0.10393165796995163, 0.11675474792718887, 0.007203542161732912, 0.0008657867438159883, 0.007421628572046757, -0.009653370827436447, -0.06819561868906021, 0.01945577934384346, 0.051638804376125336, -0.029942573979496956, -0.042958736419677734, -0.019864805042743683, 0.017653953284025192, -0.017503488808870316, -0.044733524322509766, 0.03494996204972267, -0.0019917881581932306, -0.007429750170558691, 0.023747682571411133, -0.0431840755045414, 0.0019314548699185252, -0.03294016048312187, 0.014468812383711338, -0.0024643908254802227, 0.025144264101982117, -0.022134527564048767, 0.10755819827318192, 0.02490936405956745, 0.011192023754119873, 0.0015716323396191, -0.02178562432527542, -0.06771239638328552, -0.049380138516426086, 0.08783523738384247, -0.023269586265087128, 0.009737566113471985, 0.032387129962444305, -0.052026230841875076, -0.01877208985388279, 0.06508863717317581, -0.05382818356156349, 0.039945654571056366, 0.014005248434841633, -0.004315309226512909, -0.05164776369929314, -0.039541348814964294, 0.00784064270555973, 0.008627673611044884, -0.018560588359832764, -0.01660410314798355, 0.06843478977680206, -0.04986061155796051, -0.009544438682496548, -0.043490778654813766, -0.01982610858976841, 0.05358990281820297, -0.05194596201181412, 0.00924274418503046, 0.022442573681473732, 0.054759472608566284, -0.03969776630401611, 0.04876459762454033, -0.012862351723015308, 0.04954301565885544, -0.07955924421548843, -0.04404660686850548, 0.015906522050499916, -0.01791670173406601, 0.005397598259150982, 0.0038055086042732, -0.036019161343574524, 0.013881949707865715, 0.016763104125857353, -0.034556448459625244, -0.05342577397823334, -0.01381685771048069, -0.15006470680236816, -0.019942589104175568, 0.002566175302490592, -0.02811739221215248, -0.020092783495783806, -0.015126613900065422, -0.018085237592458725, 0.10519368946552277, 0.021229058504104614, -0.019142627716064453, -0.07908312976360321, 0.006924382410943508, -0.015233058482408524, 0.026185274124145508, 0.024732710793614388, 0.060259416699409485, 0.041969891637563705, -0.026774421334266663, 0.00799805298447609, 0.011700641363859177, 0.0342189259827137, -0.03183373063802719, 0.011145621538162231, 0.03164193034172058, -0.04771155118942261, 0.026175597682595253, -0.0489879809319973, 0.06313765048980713, 0.020891299471259117, -0.020877251401543617, -0.012239369563758373, -0.030345018953084946, 0.03507860377430916, -0.05327361077070236, -0.07006189227104187, -0.025967419147491455, 0.006272461265325546, -0.018474698066711426, 0.01101798377931118, -0.026081660762429237, -0.04022398963570595, 0.037948720157146454, -0.00023168617917690426, 0.0676269382238388, -0.005176514387130737, 0.01971936598420143, -0.03912899270653725, 0.049724530428647995, 0.05640000104904175, 0.036826711148023605, 0.023012086749076843, 0.023907935246825218, -0.003595447400584817, -0.05384625121951103, 0.0001777269208105281, 0.009188906289637089, -0.05081622675061226, 0.011230272240936756, 0.016221387311816216, -0.010362103581428528, 0.030504271388053894, -0.06813428550958633, 0.045014530420303345, 0.046261951327323914, -0.019377881661057472, -0.011723337695002556, 0.012803950347006321, -0.030391035601496696, -0.0030907855834811926, 0.06818464398384094, 0.01678100973367691, 0.04427051916718483, -0.04993132874369621, 0.06181267648935318, 0.05030204355716705, 0.022441618144512177, -0.025567203760147095, -0.015064483508467674, -0.029366008937358856, -0.015265165828168392, 0.0031529932748526335, -0.08744263648986816, -0.016554730013012886, 0.033491041511297226, -0.004213474690914154, 0.0006747462321072817, -0.032266318798065186, 0.07835523039102554, -0.013851643539965153, -0.005762961693108082, -0.10156656801700592, -0.03644723445177078, -0.07768076658248901, -0.01030147634446621, 0.013028323650360107, 0.027633754536509514, -0.05577288940548897, 0.013342211954295635, -0.017482010647654533, -0.0411427803337574, 0.007647169288247824, -0.011470891535282135, 0.02215852402150631, 0.011031962931156158, 0.004099421203136444, -0.014440973289310932, -0.018185188993811607, 0.009319433942437172, 0.004363721702247858, 0.004475305322557688, 0.005963848903775215, 0.0012982389889657497, -0.07796481996774673, 0.003906753845512867, 0.023633567616343498, -0.027058854699134827, -0.000518499466124922, 0.05265210568904877, 0.05519836023449898, -0.0343669094145298, -0.02824120968580246, 0.016249554231762886, 0.0033043352887034416, 0.03540894016623497, 0.033357247710227966, -0.008044273592531681, -0.0029608916956931353, 0.024958647787570953, 0.050681307911872864, -0.037793662399053574, 0.04992763698101044, 0.0032780796755105257, -0.009910456836223602, -0.029421841725707054, -0.0147116519510746, -0.021794697269797325, 0.03465849161148071, -0.036990948021411896, 0.03658265620470047, -0.030192671343684196, -0.0320877879858017, -0.03083866462111473, -0.01527484506368637, -0.16792982816696167, -0.013539016246795654, -0.0018505020998418331, -0.01373943779617548, 0.019737526774406433, 0.02806883677840233, -0.01974073424935341, 0.0017742604250088334, -0.0052481759339571, -0.01596209593117237, 0.007207742426544428, -0.007615270093083382, 0.006253538653254509, 0.01837211474776268, 0.012095113284885883, 0.005751940421760082, -0.04393688589334488, -0.0458187460899353, 0.016736146062612534, 0.026165161281824112, -0.06021394580602646, 0.012089228257536888, 0.06863582134246826, 0.055838871747255325, 0.0484868586063385, 0.04481371119618416, 0.04715169966220856, 0.01655426062643528, -0.020898090675473213, -0.05972684919834137, -0.053977467119693756, 0.007847784087061882, 0.03233913332223892, 0.010286054573953152, 0.018272725865244865, 0.05693472921848297, 0.026759905740618706, -0.053598854690790176, -0.01714101992547512, -0.017183609306812286, 0.055396780371665955, 0.0011198350694030523, 0.027947822585701942, 0.004425154998898506, 0.011749014258384705, 0.0153060806915164, 0.005009829066693783, 0.010540829040110111, 0.048252787441015244, -0.006977658718824387, 0.011299684643745422, 0.03948843851685524, -0.009677493944764137, -0.05354953929781914, -0.008452726528048515, 0.00911550410091877, -0.01360390242189169, -0.025395328179001808, 0.031119374558329582, -0.01998763158917427, -0.05207986384630203, 0.016682274639606476, -0.015195782296359539, 0.017817987129092216, -0.005787302274256945, -0.009513536468148232, -0.01888391375541687, 0.006778006907552481, -0.03996298462152481, 0.07906286418437958, -0.04934483394026756, 0.002534460509195924, -0.0013140749651938677, 0.009739372879266739, -0.018827378749847412, 0.09211372584104538, 0.02701706625521183, 0.010106097906827927, 0.013180524110794067, 0.05087077245116234, -0.029946329072117805, 0.012760140001773834, -0.012855489738285542, 0.008200105279684067, 0.010300644673407078, -0.03887227177619934, 0.087727852165699, -0.058080825954675674, -0.013879751786589622, -0.02160850167274475, 0.05208851397037506, -0.019328616559505463, 0.003200874198228121, 0.011286824941635132, -0.0064423275180161, -0.020448535680770874, -0.018702432513237, 0.026471124961972237, -0.033904481679201126, -0.010618172585964203, 0.025642720982432365, -0.0313863642513752, -0.011534960940480232, 0.007908572442829609, -0.04512445256114006, 0.02283351682126522, 0.009164620190858841, -0.03853495419025421, -0.0023934936616569757, -0.051996540278196335, -0.010612817481160164, 0.04071998968720436, -0.00025710684712976217, -0.024372100830078125, 0.045417264103889465, 0.07408653944730759, 0.003408790100365877, 0.08287716656923294, 0.04879200458526611, 0.050907570868730545, 0.010100091807544231, 0.0189394261687994, 0.013357345014810562, 0.010168148204684258, -0.035304151475429535, 0.002700807061046362, 0.05240805447101593, 0.020336272194981575, -0.012393375858664513, 0.07442007958889008, 0.06263931095600128, 0.04272599145770073, -0.02711469493806362, -0.004798205569386482, 0.013068271800875664, -0.02986450120806694, 0.00037538332981057465, 0.013057507574558258, -0.0968465507030487, -0.01798231340944767, 0.012189477682113647, 0.03501345217227936, -0.011081080883741379, -0.01745767891407013, -0.031983938068151474, -0.022064335644245148, 0.08485711365938187, -0.00343685457482934, -0.01456260122358799, 0.005010343622416258, -0.007688052020967007, 0.024608660489320755, -0.08292613178491592, 0.06397508084774017, 0.004690829198807478, 0.007913096807897091, 0.036022353917360306, 0.0006659068749286234, -0.01658443920314312, -0.018636764958500862, 0.024615516886115074, 0.02414553053677082, -0.06473634392023087, -0.009792412631213665, -0.05325734615325928, 0.01420909259468317, -0.039277199655771255, 0.023884374648332596, 0.05650574713945389, -0.02766450308263302, -0.024189328774809837, 0.029870592057704926, -0.032924309372901917, 0.019669799134135246, -0.018359094858169556, 0.018801331520080566, -0.02707786299288273, -0.020441895350813866, 0.004687879700213671, 0.002401745645329356, 0.06377092003822327, -0.04281676188111305, -0.0009759454987943172, 0.027595609426498413, 0.060424257069826126, 0.020918354392051697, -0.005486592650413513, -0.07342268526554108, -0.0526941753923893, 0.029353946447372437, -0.03353140875697136, -0.004850347992032766, 0.04146687686443329, -0.026472879573702812, 0.01267069112509489, -0.00446405028924346, 0.010773347690701485, 0.0038922347594052553, -0.01121237687766552, 0.0022828769870102406, -0.03537539765238762, 0.014624923467636108, -0.022506799548864365, 0.042016711086034775, -0.06862662732601166, -0.013486203737556934, 0.028224986046552658, 0.002582587068900466, 0.03553735837340355, -0.015434455126523972, -0.014334972016513348, 0.004324035253375769, 0.0053898063488304615, -0.07821765542030334, -0.004852551035583019, 0.058350931853055954, 0.05561845749616623, 0.04971618577837944, 0.00848366692662239, 0.019691959023475647, 0.04842359572649002, 0.016710050404071808, -0.036617863923311234, 0.046702999621629715, -0.023141957819461823, -0.014032494276762009, -0.004935077391564846, 0.017640557140111923, 0.05168399587273598, -0.008145507425069809, 0.003850450273603201, 0.07378315180540085, -0.025645993649959564, 0.06141502037644386, -0.005647069774568081, -0.03568589314818382, -0.012221494689583778, -0.019573714584112167, -0.010537681169807911, 0.00864588562399149, 0.020921990275382996, -0.04302797093987465, -0.020178483799099922, -0.028311334550380707, 0.009283555671572685, -0.02459694817662239, 0.024087658151984215, -0.004313063342124224, -0.005432801321148872, -0.013785123825073242, 0.024139773100614548, 0.05857562646269798, -0.03191772848367691, 0.012416687794029713, 0.016925476491451263, 0.006942843087017536, 0.006598522886633873, -0.0390513651072979, -0.007005717605352402, -8.729863475309685e-05, -0.04538340121507645, 0.004946487955749035, 0.029524078592658043, -0.034420207142829895, -0.004038716200739145, -0.008144606836140156, 0.027810344472527504, 0.0006213292945176363, 0.012055370956659317, 0.0009448639466427267, 0.0028901349287480116, -0.015417925082147121, 0.015339858829975128, -0.015768028795719147, 0.007656121626496315, 0.03895176202058792, -0.011974029242992401, -0.03488216921687126, 0.0021897954866290092, 0.008017251268029213, -0.023602457717061043, 0.042762432247400284, 0.017669593915343285, 0.02949250116944313, -0.004777966067194939, 0.01222960278391838, 0.04622475057840347, 0.004831378813832998, 0.005080347880721092, -0.03096405789256096, -0.024769319221377373, -0.05760312080383301, 0.006989185232669115, -0.02802259847521782, 0.0023186085745692253, 0.024799270555377007, -0.017475241795182228, -0.02310723438858986, -0.060716282576322556, -0.05141041800379753, -0.08543168753385544, -0.031041642650961876, 0.0007977064815349877, 0.00771120423451066, -0.014823099598288536, 0.017547423020005226, 0.028314258903265, -0.01559355203062296, -0.06470701843500137, 0.022269032895565033, -0.0012528174556791782, 0.003755373414605856, 0.02596835233271122, -0.014884010888636112, -0.016153506934642792, 0.012660589069128036, 0.051579441875219345, -0.026004411280155182, -0.010785234160721302, 0.024741262197494507, -0.006832896266132593, 0.006077229045331478, -0.018859494477510452, -0.04515213519334793, -0.015692224726080894, 0.02197863720357418, 0.027596719563007355, 0.013474834151566029, -0.06793735921382904, 0.03974653407931328, 0.029159316793084145, 0.009424426592886448, 0.036018598824739456, 0.06579939275979996, 0.0007757350686006248, 0.026988979429006577, -0.023084744811058044, 0.005725073162466288, -0.009881219826638699, 0.04924647510051727, -0.04520491138100624, 0.0036490694619715214, -0.0001661169226281345, 0.01312621496617794, 0.032258667051792145, -0.04117229953408241, -0.0017563514411449432, 0.005697781685739756, -0.004057110287249088, 0.00831490196287632, -0.01355521846562624, 0.017786549404263496, 0.019952373579144478, -0.017415044829249382, 0.02924727275967598, 0.00436373008415103, -0.028496161103248596, -0.0003454386896919459, -0.028011614456772804, 0.030717402696609497, 0.029748037457466125, 0.0013926341198384762, -0.029566174373030663, 0.022096160799264908, -0.01822168380022049, -0.03222834691405296, 0.005902382079511881, -0.036765407770872116, 0.008787472732365131, -0.02015107311308384, 0.06050626561045647, -0.01662573777139187, -0.024680834263563156, 0.04925467446446419, 0.027687592431902885, -0.0594508983194828, -0.03355632722377777, -0.0018203321378678083, -0.013882149010896683, 0.03436409682035446, -0.006525041069835424, 0.02155226469039917, -0.068003810942173, 0.009525789879262447, -0.055456023663282394, -0.0006107259541749954, -0.056682657450437546, -0.03278589993715286, 0.039782535284757614, -0.0029560134280472994, 0.04285448044538498, 0.015113752335309982, -0.006758872419595718, -0.005822359584271908, -0.023287208750844002, 0.01268066093325615, 0.006393882911652327, 0.005613046232610941, -0.024748165160417557, 0.04511215165257454, 0.028768694028258324, 0.01948765106499195, 0.02212745137512684, -0.023323310539126396, 0.00483762426301837, -0.004555167630314827, 0.0469304658472538, 0.06336293369531631, 0.06120479479432106, 0.024199720472097397, -0.07068958878517151, -0.023261142894625664, -0.03503222018480301, 0.07099641114473343, 0.07402566820383072, -0.022733237594366074, -0.013286171481013298, 0.013622286729514599, -0.021212313324213028, -0.022044561803340912, -0.005962895229458809, -0.033503927290439606, -0.02475627325475216, -0.042249567806720734, 0.02494623139500618, -0.0562412291765213, -0.09909646958112717, -0.03917242959141731, -0.021050311625003815, -0.006634335964918137, -0.020698025822639465, -0.003643974894657731, -0.027524033561348915, -0.031454574316740036, -0.06287893652915955, 0.005579663440585136, -0.015219196677207947, 0.0010854346910491586, 0.03304031863808632, -0.011660171672701836, -0.030525514855980873, 0.00619041221216321, 0.028455788269639015, 0.04060158133506775, -0.036002323031425476, 0.09819784760475159, 0.001239479286596179, 0.0327460952103138, -0.05798015370965004, -0.03414849564433098, 0.033689990639686584, -0.03496948629617691]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = loader.load_embeddings()\n",
    "print(f\"Embedding Model Loaded: {embedding_model}\")\n",
    "result = embedding_model.embed_query(\"Hello, how are you?\")\n",
    "print(f\"Embedding Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a02b2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b44679a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"The Earth is the third planet from the Sun and the only known planet to support life. It has a diverse climate, ranging from arctic to tropical zones, and supports ecosystems across seven continents and five oceans.\"),\n",
    "\n",
    "    Document(page_content=\"The Industrial Revolution, beginning in the 18th century, drastically transformed human societies by shifting from manual labor to machine-based manufacturing, leading to urbanization and economic expansion globally.\"),\n",
    "\n",
    "    Document(page_content=\"The United Nations, established in 1945 after World War II, is an international organization founded to promote peace, security, human rights, and cooperation among countries. It has 193 member states.\"),\n",
    "\n",
    "    Document(page_content=\"The global economy is an interconnected system involving trade, investment, and financial flows across countries. Major players include the United States, China, the European Union, and emerging markets like India and Brazil.\"),\n",
    "\n",
    "    Document(page_content=\"Climate change refers to long-term shifts in temperatures and weather patterns. It is largely driven by human activities like burning fossil fuels, deforestation, and industrial emissions, leading to global warming and sea level rise.\"),\n",
    "\n",
    "    Document(page_content=\"Democracy is a political system in which citizens exercise power by voting. Modern democracies typically have institutions for free elections, rule of law, freedom of expression, and checks and balances.\"),\n",
    "\n",
    "    Document(page_content=\"The Internet has revolutionized communication, commerce, and education worldwide. Originating from military research in the 1960s, it now connects over 5 billion people, enabling instant global information exchange.\"),\n",
    "\n",
    "    Document(page_content=\"Renewable energy sources like solar, wind, hydro, and geothermal are critical for a sustainable future. They offer alternatives to fossil fuels, reducing carbon emissions and reliance on finite resources.\"),\n",
    "\n",
    "    Document(page_content=\"The World Health Organization (WHO) is a UN agency focused on global health issues. It coordinates international efforts to monitor diseases, set health standards, and respond to pandemics like COVID-19.\"),\n",
    "\n",
    "    Document(page_content=\"Globalization is the process of increasing interaction and integration among people, companies, and governments worldwide. It has led to greater economic growth but also raised concerns about inequality and cultural homogenization.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3b98100",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sunny\\document_portal\\env\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:83\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Chroma vector DB with persistent storage\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./chroma_db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Disk path for persistence\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\document_portal\\env\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    888\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    889\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    890\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    891\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    892\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    893\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    894\u001b[0m     client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    895\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    896\u001b[0m     collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    898\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sunny\\document_portal\\env\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:817\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[0;32m    798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \n\u001b[0;32m    800\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 817\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    818\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    819\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    820\u001b[0m         persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    821\u001b[0m         client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    822\u001b[0m         client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    823\u001b[0m         collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    825\u001b[0m     )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m         ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[1;32mc:\\Users\\sunny\\document_portal\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     emit_warning()\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\document_portal\\env\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:86\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m client_settings\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "# Chroma vector DB with persistent storage\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"  # Disk path for persistence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc156e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Persist manually (though auto-persistence happens internally)\n",
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Use the following context to answer the question.\n",
    "    If you don't know the answer, just say you don't know. Don't try to make up an answer.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5627089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL RAG Chain step-by-step\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": retriever | (lambda docs: \"\\n\\n\".join([doc.page_content for doc in docs])),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c936f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap with cache\n",
    "RAG_Cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def cached_rag_chain(query):\n",
    "    start_time = time.time()\n",
    "    if RAG_Cache.get(query):\n",
    "        print(\"***CACHE HIT***\")\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        return RAG_Cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        RAG_Cache[query] = response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19492bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is japan economy in 2024 and relation with north korea?\"\n",
    "response = cached_rag_chain(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is langchain framework?\"\n",
    "response = cached_rag_chain(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ae0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Why United Nations, established in 1945 after World War II?\"\n",
    "response = cached_rag_chain(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008817ed",
   "metadata": {},
   "source": [
    "## Cache Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from typing import Any, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebuggableCache(InMemoryCache):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._cache: Dict[Tuple[str, str], Any] = {}\n",
    "\n",
    "    def lookup(self, prompt: str, llm_string: str):\n",
    "        return self._cache.get((prompt, llm_string))\n",
    "\n",
    "    def update(self, prompt: str, llm_string: str, return_val: Any):\n",
    "        self._cache[(prompt, llm_string)] = return_val\n",
    "\n",
    "    def view_cache(self):  # this is our custom method\n",
    "        return self._cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e663ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg_cache = DebuggableCache()\n",
    "set_llm_cache(dbg_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06147a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d480168",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCache Contents:\")\n",
    "for k, v in dbg_cache.view_cache().items():\n",
    "    print(f\"Prompt: {k[0]} | Cached Output: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e79f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCache Contents:\")\n",
    "for k, v in dbg_cache.view_cache().items():\n",
    "    print(f\"Prompt: {k[0]} | Cached Output: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbe572",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is the capital of india?\")\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCache Contents:\")\n",
    "for k, v in dbg_cache.view_cache().items():\n",
    "    print(f\"Prompt: {k[0]} | Cached Output: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is the capital of india?\")\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7707f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"give me 1000 lines of essay on science and give the importance of it regarding mathematics?\")\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9df7df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Okay, here's a joke about LangChain and ECS:\n",
      "\n",
      "Why did the LangChain agent refuse to deploy on ECS?\n",
      "\n",
      "Because it kept saying, \"I can't find the context! I need more environment variables! And where's my vector database? This feels like a container without a purpose... I'm going back to my Jupyter notebook!\"\n",
      "Token Usage Stats: Tokens Used: 84\n",
      "\tPrompt Tokens: 9\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 75\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "with get_openai_callback() as cb:\n",
    "    response = llm.invoke(\"Tell me a joke about LangChain and ECS\")\n",
    "    print(\"Response:\", response.content)\n",
    "    print(\"Token Usage Stats:\", cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "216b5232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What is Retrieval-Augmented Generation?\n",
      "A: Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by allowing them to access and incorporate information from external knowledge sources during the generation process.  Think of it as giving an LLM a textbook or a library to consult before answering a question.\n",
      "\n",
      "Here's a breakdown of the key components and how it works:\n",
      "\n",
      "**1. The Problem RAG Solves:**\n",
      "\n",
      "* **LLMs have limited knowledge:** LLMs are trained on massive datasets, but their knowledge is frozen in time. They can't access real-time information or specific domain knowledge that wasn't included in their training data.\n",
      "* **Hallucinations:** LLMs can sometimes generate incorrect or nonsensical information, often referred to as \"hallucinations.\" This happens because they're trying to answer questions based on patterns learned during training, even if they don't have the actual facts.\n",
      "* **Lack of Transparency:** It's often difficult to understand why an LLM generated a particular response.  Without access to the source material, it's hard to verify the accuracy or relevance of the information.\n",
      "\n",
      "**2. How RAG Works:**\n",
      "\n",
      "RAG addresses these limitations by adding a retrieval step before the generation step.  Here's the typical process:\n",
      "\n",
      "* **a. User Query:** The user asks a question or provides a prompt.\n",
      "\n",
      "* **b. Retrieval:**\n",
      "    * **Indexing:**  The external knowledge source (e.g., a document database, a website, a knowledge graph) is indexed. This involves breaking down the information into smaller chunks (e.g., paragraphs, sentences) and creating vector embeddings for each chunk.  Vector embeddings are numerical representations that capture the semantic meaning of the text.\n",
      "    * **Similarity Search:** The user's query is also converted into a vector embedding.  Then, a similarity search is performed to find the chunks in the indexed knowledge source that are most semantically similar to the query.  This is often done using techniques like cosine similarity or dot product.\n",
      "\n",
      "* **c. Augmentation:** The retrieved chunks of information are combined with the original user query. This augmented prompt now contains both the user's question and relevant context from the external knowledge source.\n",
      "\n",
      "* **d. Generation:** The augmented prompt is fed into the LLM. The LLM uses this information to generate a more informed and accurate response.\n",
      "\n",
      "**3. Key Components in Detail:**\n",
      "\n",
      "* **Knowledge Source:** This is the external data source that the LLM will use to augment its knowledge. It can be:\n",
      "    * **Document Databases:** Collections of text documents (e.g., PDFs, Word documents, web pages).\n",
      "    * **Knowledge Graphs:** Structured representations of knowledge, with entities and relationships between them.\n",
      "    * **APIs:**  Allow access to real-time data from external services.\n",
      "    * **Databases:** Structured data stored in tables.\n",
      "\n",
      "* **Indexing:** The process of preparing the knowledge source for efficient retrieval.  This typically involves:\n",
      "    * **Chunking:** Dividing the data into smaller, manageable units.\n",
      "    * **Embedding:** Converting each chunk into a vector embedding using a pre-trained language model (e.g., Sentence Transformers, OpenAI Embeddings).\n",
      "\n",
      "* **Retrieval Model:**  The algorithm used to find the most relevant chunks of information based on the user's query.  Common techniques include:\n",
      "    * **Semantic Search:**  Finding chunks that are semantically similar to the query, even if they don't contain the exact same keywords.\n",
      "    * **Keyword Search:**  Finding chunks that contain specific keywords from the query.\n",
      "\n",
      "* **Large Language Model (LLM):** The model that generates the final response based on the augmented prompt.  Examples include:\n",
      "    * **GPT-3, GPT-4 (OpenAI)**\n",
      "    * **LaMDA (Google)**\n",
      "    * **LLaMA (Meta)**\n",
      "    * **Claude (Anthropic)**\n",
      "\n",
      "**4. Benefits of RAG:**\n",
      "\n",
      "* **Improved Accuracy:** By grounding the LLM's responses in external knowledge, RAG reduces the likelihood of hallucinations and improves the accuracy of the generated text.\n",
      "* **Up-to-Date Information:** RAG allows LLMs to access and incorporate real-time information, making them more useful for tasks that require current knowledge.\n",
      "* **Domain-Specific Knowledge:** RAG can be used to tailor LLMs to specific domains by providing them with access to relevant domain-specific knowledge sources.\n",
      "* **Transparency and Explainability:** RAG provides a way to trace the source of the information used to generate a response, making the process more transparent and explainable.  You can see which documents or data points the LLM used to form its answer.\n",
      "* **Reduced Training Costs:** Instead of retraining the entire LLM with new data, RAG allows you to update the knowledge source independently, which is more efficient and cost-effective.\n",
      "\n",
      "**5. Challenges of RAG:**\n",
      "\n",
      "* **Retrieval Quality:** The quality of the retrieved information is crucial. If the retrieval model fails to find relevant information, the LLM will still generate a poor response.\n",
      "* **Chunking Strategy:**  Choosing the right chunk size is important.  Too small, and the context is lost.  Too large, and the retrieval becomes less precise.\n",
      "* **Computational Cost:**  Indexing and retrieving information can be computationally expensive, especially for large knowledge sources.\n",
      "* **Noise in Retrieved Context:**  The retrieved context might contain irrelevant or noisy information, which can negatively impact the LLM's performance.\n",
      "* **Prompt Engineering:**  Crafting effective prompts that guide the LLM to use the retrieved information effectively is important.\n",
      "\n",
      "**6. Use Cases:**\n",
      "\n",
      "* **Question Answering:** Answering questions based on a specific document or knowledge base.\n",
      "* **Chatbots:** Building chatbots that can provide accurate and informative responses to user queries.\n",
      "* **Content Generation:** Generating articles, reports, or other types of content based on external data sources.\n",
      "* **Code Generation:** Generating code snippets based on documentation or API specifications.\n",
      "* **Summarization:** Summarizing long documents or articles.\n",
      "\n",
      "**In summary, Retrieval-Augmented Generation is a powerful technique that combines the strengths of retrieval-based and generation-based approaches to create more accurate, informative, and transparent LLM applications.** It's a rapidly evolving field with ongoing research focused on improving the efficiency and effectiveness of the retrieval and generation processes.\n",
      "\n",
      "Q: How does FAISS indexing work?\n",
      "A: FAISS (Facebook AI Similarity Search) is a library designed for efficient similarity search and clustering of dense vectors. It's particularly useful for large datasets where brute-force search becomes computationally expensive. Here's a breakdown of how FAISS indexing works, covering the key concepts and techniques:\n",
      "\n",
      "**1. The Problem: Nearest Neighbor Search**\n",
      "\n",
      "The core problem FAISS addresses is finding the *k* nearest neighbors (k-NN) to a query vector within a large dataset of vectors.  A naive approach would involve calculating the distance between the query vector and every vector in the dataset, which is O(N) complexity (where N is the number of vectors).  For millions or billions of vectors, this is impractical.\n",
      "\n",
      "**2. FAISS's Approach: Approximate Nearest Neighbor (ANN) Search**\n",
      "\n",
      "FAISS uses various techniques to perform *approximate* nearest neighbor search.  This means it might not always find the absolute closest neighbors, but it finds neighbors that are very close with high probability, and it does so much faster than brute-force.  The trade-off is accuracy for speed.\n",
      "\n",
      "**3. Key Concepts and Techniques**\n",
      "\n",
      "*   **Vector Quantization:** This is a fundamental technique used in many FAISS indexes.  It involves dividing the vector space into a set of discrete regions (cells or clusters) represented by *centroids*.  Instead of comparing the query vector to every vector in the dataset, you first find the closest centroid and then only compare the query vector to the vectors within that centroid's region.  This significantly reduces the search space.\n",
      "\n",
      "*   **Index Types:** FAISS offers a wide variety of index types, each optimized for different scenarios (dataset size, vector dimensionality, accuracy requirements, memory constraints, etc.).  Here are some common ones:\n",
      "\n",
      "    *   **Flat Index:** This is the simplest index. It stores the vectors directly and performs a brute-force search.  It's accurate but slow for large datasets.  Useful as a baseline.\n",
      "\n",
      "    *   **IVF (Inverted File):**  This is a popular and versatile index.  It combines vector quantization with an inverted index.\n",
      "        *   **Training:**  A set of vectors is used to train a quantizer (e.g., k-means).  The quantizer learns the centroids of the clusters.\n",
      "        *   **Indexing:** Each vector in the dataset is assigned to the closest centroid (cluster).  An inverted index is created, mapping each centroid to the list of vectors belonging to that cluster.\n",
      "        *   **Searching:**  The query vector is compared to a small number of centroids (controlled by the `nprobe` parameter).  The vectors within the corresponding clusters are then searched exhaustively.  Increasing `nprobe` increases accuracy but also increases search time.\n",
      "\n",
      "    *   **PQ (Product Quantization):**  This technique divides the vector into subvectors and quantizes each subvector independently.  This allows for a more compact representation of the vectors, reducing memory usage.  It's often used in combination with IVF (IVF-PQ).\n",
      "\n",
      "    *   **HNSW (Hierarchical Navigable Small World):**  This is a graph-based index that builds a multi-layered graph structure.  Each layer represents the data at a different level of granularity.  Searching involves traversing the graph from the top layer to the bottom, progressively refining the search.  HNSW is known for its good accuracy and speed, especially for high-dimensional data.\n",
      "\n",
      "    *   **OPQ (Optimized Product Quantization):**  An extension of PQ that learns a rotation matrix to pre-process the vectors before applying PQ. This can improve the accuracy of the quantization.\n",
      "\n",
      "*   **Distance Metrics:** FAISS supports various distance metrics, including:\n",
      "\n",
      "    *   **L2 (Euclidean) distance:** The most common distance metric.\n",
      "    *   **Inner Product (Dot Product):**  Useful for cosine similarity.\n",
      "    *   **L1 (Manhattan) distance:** Less common but can be useful in some cases.\n",
      "\n",
      "*   **Training:** Many FAISS indexes require a training step.  This involves providing a representative subset of the data to the index so it can learn the data distribution and optimize its internal parameters (e.g., cluster centroids for IVF).\n",
      "\n",
      "*   **Parameters:**  FAISS indexes have various parameters that control their behavior, such as:\n",
      "\n",
      "    *   `nlist`: The number of clusters in an IVF index.\n",
      "    *   `nprobe`: The number of clusters to search during a query in an IVF index.\n",
      "    *   `M`: The number of subvectors in a PQ index.\n",
      "    *   `efConstruction`:  A parameter in HNSW that controls the quality of the graph during construction.\n",
      "    *   `efSearch`: A parameter in HNSW that controls the search effort.\n",
      "\n",
      "**4. Workflow**\n",
      "\n",
      "1.  **Data Preparation:**  Convert your data into a matrix of dense vectors (e.g., NumPy array).  Ensure the data type is appropriate (e.g., `float32`).\n",
      "\n",
      "2.  **Index Selection:** Choose the appropriate index type based on your data size, dimensionality, accuracy requirements, and memory constraints.  Experimentation is often necessary to find the best index for your specific use case.\n",
      "\n",
      "3.  **Training (if required):**  Train the index using a representative subset of your data.\n",
      "\n",
      "4.  **Indexing:** Add the vectors to the index.\n",
      "\n",
      "5.  **Searching:**  Perform similarity searches using query vectors.  Adjust the index parameters (e.g., `nprobe` for IVF, `efSearch` for HNSW) to balance accuracy and speed.\n",
      "\n",
      "**5. Example (Simplified IVF)**\n",
      "\n",
      "Let's illustrate the IVF index with a simplified example:\n",
      "\n",
      "1.  **Training:**\n",
      "    *   You have 1000 vectors.\n",
      "    *   You choose `nlist = 10` (10 clusters).\n",
      "    *   You train a k-means algorithm on a subset of the 1000 vectors to find 10 cluster centroids.\n",
      "\n",
      "2.  **Indexing:**\n",
      "    *   For each of the 1000 vectors, you find the closest centroid.\n",
      "    *   You create an inverted index:\n",
      "        *   Centroid 1: [vector_id_1, vector_id_5, vector_id_12, ...]\n",
      "        *   Centroid 2: [vector_id_2, vector_id_8, vector_id_20, ...]\n",
      "        *   ...\n",
      "        *   Centroid 10: [vector_id_3, vector_id_9, vector_id_15, ...]\n",
      "\n",
      "3.  **Searching:**\n",
      "    *   You have a query vector.\n",
      "    *   You choose `nprobe = 2` (search 2 clusters).\n",
      "    *   You find the 2 closest centroids to the query vector (e.g., Centroids 3 and 7).\n",
      "    *   You retrieve the vectors associated with Centroids 3 and 7 from the inverted index.\n",
      "    *   You calculate the distances between the query vector and all the vectors in those two clusters.\n",
      "    *   You return the `k` nearest neighbors from those vectors.\n",
      "\n",
      "**6. Advantages of FAISS**\n",
      "\n",
      "*   **Speed:**  Significantly faster than brute-force search for large datasets.\n",
      "*   **Scalability:**  Handles millions or billions of vectors.\n",
      "*   **Memory Efficiency:**  Offers techniques like PQ to reduce memory usage.\n",
      "*   **Flexibility:**  Provides a wide range of index types and distance metrics.\n",
      "*   **GPU Support:**  Can leverage GPUs for even faster search.\n",
      "*   **Open Source:**  Freely available and actively maintained.\n",
      "\n",
      "**7. Considerations**\n",
      "\n",
      "*   **Accuracy vs. Speed Trade-off:**  ANN search is approximate, so you need to balance accuracy and speed by tuning the index parameters.\n",
      "*   **Index Selection:**  Choosing the right index type is crucial for performance.  Experimentation is often required.\n",
      "*   **Training Data:**  The quality of the training data can affect the accuracy of the index.\n",
      "*   **Parameter Tuning:**  Optimizing the index parameters can significantly improve performance.\n",
      "\n",
      "In summary, FAISS provides a powerful set of tools for efficient similarity search in large datasets. By using techniques like vector quantization and inverted indexes, it significantly reduces the search space, enabling fast and scalable nearest neighbor search. Understanding the different index types and their parameters is key to effectively using FAISS for your specific application.\n",
      "\n",
      "Q: What is the difference between fine-tuning and RAG?\n",
      "A: Both fine-tuning and Retrieval-Augmented Generation (RAG) are techniques used to improve the performance of Large Language Models (LLMs) on specific tasks or with specific knowledge. However, they achieve this in fundamentally different ways:\n",
      "\n",
      "**Fine-tuning:**\n",
      "\n",
      "*   **Mechanism:** Modifies the internal parameters (weights) of the LLM itself. It's like teaching the LLM new skills or refining its existing ones by showing it a lot of examples.\n",
      "*   **Process:** Requires a dataset of labeled examples relevant to the target task. The LLM is trained on this dataset, adjusting its internal parameters to better predict the correct outputs.\n",
      "*   **Knowledge Integration:** Directly embeds new knowledge into the LLM's parameters. The model *learns* the information and can recall it directly from its memory.\n",
      "*   **Advantages:**\n",
      "    *   Can lead to better performance on tasks that require complex reasoning or understanding of nuanced patterns in the training data.\n",
      "    *   Faster inference speed once fine-tuning is complete, as the knowledge is already integrated into the model.\n",
      "    *   Can improve the model's ability to follow specific instructions or adopt a particular style.\n",
      "*   **Disadvantages:**\n",
      "    *   Requires a significant amount of labeled data, which can be expensive and time-consuming to create.\n",
      "    *   Can be computationally expensive and time-consuming to train.\n",
      "    *   Risk of overfitting to the training data, leading to poor generalization on unseen data.\n",
      "    *   \"Catastrophic forgetting\": The model might forget previously learned information during fine-tuning.\n",
      "    *   Difficult to update the model with new information after fine-tuning without retraining.\n",
      "    *   Can be harder to interpret and control the model's behavior after fine-tuning.\n",
      "\n",
      "**Retrieval-Augmented Generation (RAG):**\n",
      "\n",
      "*   **Mechanism:** Augments the LLM's input with relevant information retrieved from an external knowledge source (e.g., a database, a collection of documents, or the internet).\n",
      "*   **Process:**\n",
      "    1.  The user's query is used to retrieve relevant information from the external knowledge source.\n",
      "    2.  The retrieved information is combined with the original query and fed into the LLM.\n",
      "    3.  The LLM generates a response based on both the query and the retrieved information.\n",
      "*   **Knowledge Integration:** Doesn't directly embed knowledge into the LLM. Instead, it provides the LLM with the necessary information at the time of inference.\n",
      "*   **Advantages:**\n",
      "    *   Doesn't require retraining the LLM, making it more efficient and cost-effective.\n",
      "    *   Allows the LLM to access and utilize a vast amount of information that it wasn't trained on.\n",
      "    *   Easier to update the knowledge source with new information without affecting the LLM.\n",
      "    *   More transparent and controllable, as the retrieved information provides context for the LLM's response.\n",
      "    *   Reduces the risk of hallucination (generating incorrect or nonsensical information) by grounding the LLM in factual knowledge.\n",
      "*   **Disadvantages:**\n",
      "    *   Performance depends on the quality of the retrieval mechanism and the knowledge source.\n",
      "    *   Can be slower than fine-tuning, as it requires retrieving information before generating a response.\n",
      "    *   The LLM may struggle to integrate the retrieved information effectively, especially if it's poorly formatted or irrelevant.\n",
      "    *   Requires managing and maintaining the external knowledge source.\n",
      "\n",
      "**Here's an analogy:**\n",
      "\n",
      "*   **Fine-tuning:**  Imagine teaching a student a new subject by having them study a textbook and do practice problems. The student internalizes the knowledge and can answer questions directly from memory.\n",
      "*   **RAG:** Imagine giving a student access to a library while they're taking a test. They can look up information in the library to help them answer the questions.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "| Feature          | Fine-tuning                               | RAG                                         |\n",
      "|-------------------|-------------------------------------------|---------------------------------------------|\n",
      "| **Mechanism**    | Modifies LLM parameters                  | Augments LLM input with retrieved data     |\n",
      "| **Knowledge**    | Embedded in LLM                          | External knowledge source                   |\n",
      "| **Training**     | Requires training data and retraining     | No retraining required                      |\n",
      "| **Update**       | Difficult to update                       | Easy to update                               |\n",
      "| **Speed**        | Faster inference                          | Slower inference (due to retrieval)         |\n",
      "| **Data Needs**   | Large, labeled dataset                    | External knowledge source (can be unlabeled) |\n",
      "| **Hallucination**| Higher risk                               | Lower risk                                  |\n",
      "\n",
      "**When to use which?**\n",
      "\n",
      "*   **Fine-tuning:** Use when you need to improve the LLM's performance on a specific task that requires complex reasoning or understanding of nuanced patterns, and you have a good amount of labeled data.  Also useful when you need the fastest possible inference speed.\n",
      "*   **RAG:** Use when you need to provide the LLM with access to a large and constantly evolving knowledge base, and you want to avoid retraining the LLM.  Also useful when you want to reduce the risk of hallucination and provide more transparent and controllable responses.\n",
      "\n",
      "In some cases, a combination of both fine-tuning and RAG can be used to achieve optimal performance. For example, you might fine-tune an LLM to be better at using a specific retrieval system, and then use RAG to provide it with the necessary information at inference time.\n",
      "\n",
      "=== Token Usage Summary ===\n",
      "Total Tokens: 4357\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 4331\n",
      "Total Cost (USD): $0.000000\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is Retrieval-Augmented Generation?\",\n",
    "    \"How does FAISS indexing work?\",\n",
    "    \"What is the difference between fine-tuning and RAG?\"\n",
    "]\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for q in questions:\n",
    "        answer = llm.invoke(q)\n",
    "        print(f\"\\nQ: {q}\\nA: {answer.content}\")\n",
    "\n",
    "    print(\"\\n=== Token Usage Summary ===\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff0aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
